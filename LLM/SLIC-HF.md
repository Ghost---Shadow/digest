# SLiC-HF: Sequence Likelihood Calibration with Human Feedback

## [SLiC-HF: Sequence Likelihood Calibration with Human Feedback](https://arxiv.org/abs/2305.10425)

**Source Code:** Nope

**Datasets:** TL;DR

**Time to read (minute):** 110 mins

**Easy to read?** Yes

**Author:** Google

**Year of Submission:** 2023

### What problem does it solve?

Easier than PPO loss but does the same thing

### How does it solve it?

```python
import torch
import torch.nn.functional as F

def slic_loss(model, x, y_pos, y_neg, y_ref, delta, lambda_reg):
    """
    SLiC-HF loss function.

    Args:
        model: The model being trained.
        x: The input sequence.
        y_pos: The positive sequence.
        y_neg: The negative sequence.
        y_ref: The target sequence.
        delta: The margin for the ranking loss.
        lambda_reg: The regularization weight.

    Returns:
        The computed loss.
    """
    # Forward pass through the model for each sequence
    logits_pos = model(x, y_pos)
    logits_neg = model(x, y_neg)
    logits_ref = model(x, y_ref)

    # Calculate the log probabilities of the sequences
    log_prob_y_pos = F.log_softmax(logits_pos, dim=-1).gather(1, y_pos.unsqueeze(-1)).squeeze(-1).sum(dim=-1)
    log_prob_y_neg = F.log_softmax(logits_neg, dim=-1).gather(1, y_neg.unsqueeze(-1)).squeeze(-1).sum(dim=-1)
    log_prob_y_ref = F.log_softmax(logits_ref, dim=-1).gather(1, y_ref.unsqueeze(-1)).squeeze(-1).sum(dim=-1)

    # Calculate the calibration loss
    calibration_loss = F.relu(delta - log_prob_y_pos + log_prob_y_neg)

    # Calculate the regularization loss
    regularization_loss = lambda_reg * log_prob_y_ref

    # Combine the losses
    loss = calibration_loss - regularization_loss

    return loss.mean()
```

#### Dataset

TL;DR dataset

document, summary1, summary2, label (which summary is better)

#### Model

T5 large

### How is this paper novel?

Much easier training than PPO

### Key takeaways

* allows token wise training
* allows offline training

> The key takeaway from this paper is that the SLiC-HF method can effectively leverage human feedback data to improve the quality of text summaries generated by machine learning models. The authors find that the SLiC-HF method outperforms the baseline models in their experiments, and they also observe that the summaries generated by the models trained with SLiC-HF tend to be longer on average.

### What I still do not understand?

none

### Ideas to pursue

* somehow use feedback as text instead of labels to guide the generation

> One potential idea to pursue is to apply the SLiC-HF method to other types of text generation tasks, such as translation or dialogue generation. It could also be interesting to experiment with different types of ranking models or different methods for collecting human feedback data. Additionally, further research could be conducted to investigate the reasons for the observed increase in the average length of the summaries and to develop methods for controlling this length.
