# Quick papers

## [Active Labeling: Streaming Stochastic Gradients](https://proceedings.neurips.cc/paper_files/paper/2022/hash/6fee03d84375a159ecd3769ebbacae83-Abstract-Conference.html)

Use the magnitude of a random projection of the model's gradients as a learning rate multiplier.

## [Active Learning for Multiple Target Models](https://proceedings.neurips.cc/paper_files/paper/2022/hash/faacb7a4827b4d51e201666b93ab5fa7-Abstract-Conference.html)

1. Shortlist datapoints which are most disagreed among a mixture of models
2. Shortlist models based on accuracy difference from the best model so far

## [Active Learning Helps Pretrained Models Learn the Intended Task](https://proceedings.neurips.cc/paper_files/paper/2022/hash/b43a0e8a35b1c044b18cd843b9771915-Abstract-Conference.html)

active learning on untrained models do more harm than good

## [Efficient Active Learning with Abstention](https://proceedings.neurips.cc/paper_files/paper/2022/file/e5aa7171449b83f8b4eec1623eac9906-Supplemental-Conference.pdf)

If the model predicts "I dont know" then dont lookup the real groundtruth y.
