# Augmented Models

## [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426)

**Source Code:** [???]()

**Datasets:**

**Time to read:**

**Author:** Lots

**Year of Submission:** 2021

### What problem does it solve?

Retreival augmented LLM

### How does it solve it?

#### Model

### How is this paper novel?

* Chunked cross attention
* To our knowledge, our work is the first to show the benefits of scaling the retrieval database to trillions of tokens for large parametric language models.
* Proximity aware evaluation

### Key takeaways

### What I still do not understand?

* "when using up to 40 neighbours. "
* Likelihood of tokens from the first chunk does not depend on any retrieval data

### Ideas to pursue

* todo

2.2
